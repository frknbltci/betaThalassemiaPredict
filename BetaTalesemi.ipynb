{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**NORMALİZASYON UYGULANMADAN ÖNCE**\n",
      "Standard Deviation =  12.439083076337319\n",
      "Mean Value =  131.02199312714777\n",
      "Entropi Value =  1\n",
      "Basit kare integrali =  17321.493470790378\n",
      "Dalga boyu =  1\n",
      "**NORMALİZASYONDAN SONRAKİ VERİLER**\n",
      "Standard Deviation =  0.31097707690843296\n",
      "Mean Value =  0.5255498281786941\n",
      "Entropi Value =  1\n",
      "Basit kare integrali =  0.3729093642611684\n",
      "Dalga boyu =  0.4\n",
      "    Entropi  Standart Sapma  Ortalama Mutlak Değer  Basit Kare İntegral  \\\n",
      "ıd                                                                        \n",
      "1     0.880           0.044                  0.327                0.333   \n",
      "2     0.986           0.049                  0.109                0.185   \n",
      "3     0.230           0.011                  0.812                0.833   \n",
      "4     0.124           0.006                  1.000                0.981   \n",
      "5     1.000           0.050                  0.000                0.000   \n",
      "6     0.828           0.615                  0.066                0.028   \n",
      "7     0.328           0.769                  0.711                0.778   \n",
      "8     0.167           0.385                  0.855                0.889   \n",
      "9     0.661           0.692                  0.276                0.278   \n",
      "10    0.005           0.000                  1.000                1.000   \n",
      "11    0.034           0.144                  0.044                0.237   \n",
      "12    0.651           1.000                  0.502                0.386   \n",
      "13    0.074           0.000                  1.000                0.500   \n",
      "14    0.651           1.000                  0.502                0.386   \n",
      "15    1.000           0.054                  0.043                1.000   \n",
      "16    0.709           1.000                  1.000                0.911   \n",
      "17    0.046           0.188                  0.157                0.192   \n",
      "18    0.999           0.000                  0.000                0.263   \n",
      "19    0.689           0.049                  0.012                1.000   \n",
      "20    0.000           0.788                  0.275                0.035   \n",
      "21    0.000           0.081                  0.333                0.160   \n",
      "22    0.666           0.363                  0.666                0.381   \n",
      "23    0.666           0.018                  1.000                0.588   \n",
      "24    1.000           0.000                  1.000                0.747   \n",
      "25    0.000           0.090                  0.000                0.215   \n",
      "26    0.000           0.818                  0.333                0.251   \n",
      "27    0.666           0.181                  1.000                0.748   \n",
      "28    0.333           0.636                  0.333                0.342   \n",
      "29    1.000           0.000                  1.000                0.971   \n",
      "30    0.666           0.363                  0.666                0.525   \n",
      "\n",
      "    Dalga boyu  Grup Tipi  \n",
      "ıd                         \n",
      "1        1.000          0  \n",
      "2        0.400          0  \n",
      "3        0.200          0  \n",
      "4        0.600          0  \n",
      "5        0.800          0  \n",
      "6        0.500          1  \n",
      "7        0.000          1  \n",
      "8        0.167          1  \n",
      "9        1.000          1  \n",
      "10       0.500          1  \n",
      "11       0.069          0  \n",
      "12       0.034          0  \n",
      "13       0.428          0  \n",
      "14       0.034          0  \n",
      "15       0.641          1  \n",
      "16       0.034          1  \n",
      "17       0.000          1  \n",
      "18       0.199          1  \n",
      "19       0.662          0  \n",
      "20       0.255          1  \n",
      "21       0.810          0  \n",
      "22       0.444          0  \n",
      "23       0.212          0  \n",
      "24       0.023          0  \n",
      "25       0.855          0  \n",
      "26       1.000          1  \n",
      "27       0.265          1  \n",
      "28       0.839          1  \n",
      "29       0.013          1  \n",
      "30       0.517          1  \n",
      "(20, 26)\n",
      "(20, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fbalt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "C:\\Users\\fbalt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:390: DeprecationWarning: The 'categorical_features' keyword is deprecated in version 0.20 and will be removed in 0.22. You can use the ColumnTransformer instead.\n",
      "  \"use the ColumnTransformer instead.\", DeprecationWarning)\n",
      "C:\\Users\\fbalt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:212: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, activation=\"relu\", input_dim=5, kernel_initializer=\"uniform\")`\n",
      "C:\\Users\\fbalt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:213: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(3, activation=\"relu\", kernel_initializer=\"uniform\")`\n",
      "C:\\Users\\fbalt\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:214: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected dense_241_input to have shape (5,) but got array with shape (26,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-111-0fb25273d0c2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    219\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 221\u001b[1;33m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    222\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 952\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m    953\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# Don't enforce the batch size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 751\u001b[1;33m             exception_prefix='input')\n\u001b[0m\u001b[0;32m    752\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\keras\\engine\\training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    136\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking input: expected dense_241_input to have shape (5,) but got array with shape (26,)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import xlrd \n",
    "\n",
    "# Import necessary modules\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Keras specific\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical \n",
    "\n",
    "\n",
    "f = open(\"HBB12.txt\", \"r\")\n",
    "hbb = str(f.read())\n",
    "\n",
    "\n",
    "def integerMapping(hbb):\n",
    "    sequence = []\n",
    "    for i in hbb:\n",
    "        if i == 'A':\n",
    "            sequence.append(0)\n",
    "        if i == 'C':\n",
    "            sequence.append(1)\n",
    "        if i == 'T':\n",
    "            sequence.append(2)\n",
    "        if i == 'G':\n",
    "            sequence.append(3)\n",
    "    return sequence\n",
    "\n",
    "def reelMapping(hbb):\n",
    "    sequence = []\n",
    "    for i in hbb:\n",
    "        if i == 'A':\n",
    "            sequence.append(-1.5)\n",
    "        if i == 'C':\n",
    "            sequence.append(0.5)\n",
    "        if i == 'T':\n",
    "            sequence.append(1.5)\n",
    "        if i == 'G':\n",
    "            sequence.append(-0.5)\n",
    "    return sequence\n",
    "\n",
    "\n",
    "beforeNormSequence = []\n",
    "\n",
    "def moolMassMapping(hbb):\n",
    "    \n",
    "    for i in hbb:\n",
    "        if i == 'A':\n",
    "            beforeNormSequence.append(134)\n",
    "        if i == 'C':\n",
    "            beforeNormSequence.append(110)\n",
    "        if i == 'T':\n",
    "            beforeNormSequence.append(125)\n",
    "        if i == 'G':\n",
    "            beforeNormSequence.append(150)\n",
    "    return beforeNormSequence\n",
    "\n",
    "\n",
    "def atomicMapping(hbb):\n",
    "    sequence = []\n",
    "    for i in hbb:\n",
    "        if i == 'A':\n",
    "            sequence.append(70)\n",
    "        if i == 'C':\n",
    "            sequence.append(58)\n",
    "        if i == 'T':\n",
    "            sequence.append(66)\n",
    "        if i == 'G':\n",
    "            sequence.append(78)\n",
    "    return sequence\n",
    "\n",
    "#MIN MAX NORMALİZASYONU KULLANILDI\n",
    "def normalizasyon(letterseq):\n",
    "    score = []\n",
    "    for i in range(0,len(letterseq)):\n",
    "        score.append((letterseq[i]-110)/(40))\n",
    "    return score\n",
    "        \n",
    "\n",
    "def spectrum (letterseq):\n",
    "    score = 0\n",
    "    for i in range(1,len(letterseq)-1):\n",
    "        score += letterseq[i+1]-letterseq[i]\n",
    "    if score >=1 :\n",
    "        score=1\n",
    "        return score\n",
    "    elif score<=0:\n",
    "        score=0\n",
    "        return score\n",
    "    else:\n",
    "        return score\n",
    "    \n",
    "\n",
    "\n",
    "#Entropi Hesabı Kaynak https://medium.com/@sddkal/python-entropi-ve-bilgi-kazanc%C4%B1-hesab%C4%B1-692261b71bd6\n",
    "class forEntropi:\n",
    "    \"\"\" Utility functions \"\"\"\n",
    "    @staticmethod\n",
    "    def getFreqs(data, only_freqs=True):\n",
    "        \"\"\" Her kume elemaninin gorulme frekansi\"\"\"\n",
    "        arr = np.unique(data,return_counts=True)\n",
    "        if not only_freqs:\n",
    "            return arr[0], arr[1] / np.sum(arr[1],dtype=np.float)\n",
    "        return arr[1] / np.sum(arr[1],dtype=np.float)\n",
    "\n",
    "    @staticmethod\n",
    "    def entropy(data_column):\n",
    "        \"\"\" Bir veri kumesi icin entropi tanimi -pa * logpa -pb * logpb - pc * logpc ... \"\"\"\n",
    "        # getFreqs ile her elemanin olasiligini(gorulme frekansi / toplam eleman sayisi) elde ediyoruz\n",
    "        freq = forEntropi.getFreqs(data_column)\n",
    "        e = -1*freq*np.log2(freq)\n",
    "        if np.sum(e)>=1:\n",
    "             return 1\n",
    "        elif np.sum(e)<=0:\n",
    "             return 0  \n",
    "        else: \n",
    "            return np.sum(e)\n",
    "    \n",
    "letterseq1 = []\n",
    "letterseq1 = moolMassMapping(hbb);\n",
    "\n",
    "\n",
    "    #NORMALİZASYON UYGULANMADAN ÖNCEKİ DEĞERLER\n",
    "print(\"**NORMALİZASYON UYGULANMADAN ÖNCE**\")\n",
    "        \n",
    "#standart sapma\n",
    "stdeviation = np.std(letterseq1)\n",
    "#mean value\n",
    "meanvalue = np.mean(letterseq1)\n",
    "#square power\n",
    "squarepower = np.sum(np.power(letterseq1,2))/len(letterseq1) #incelenecek\n",
    "#entropi\n",
    "entropi = forEntropi.entropy(letterseq1)\n",
    "#Spectrum\n",
    "dalgaBoyu = spectrum(letterseq1)\n",
    "\n",
    "print(\"Standard Deviation = \" , stdeviation)\n",
    "print(\"Mean Value = \" , meanvalue)\n",
    "print(\"Entropi Value = \" , entropi)\n",
    "print(\"Basit kare integrali = \" , squarepower)\n",
    "print(\"Dalga boyu = \" , dalgaBoyu)\n",
    "\n",
    "\n",
    "print(\"**NORMALİZASYONDAN SONRAKİ VERİLER**\")\n",
    "letterseq = []\n",
    "letterseq = normalizasyon(letterseq1)\n",
    "\n",
    "\n",
    "\n",
    "#standart sapma\n",
    "stdeviation = np.std(letterseq)\n",
    "#mean value\n",
    "meanvalue = np.mean(letterseq)\n",
    "#square power\n",
    "squarepower = np.sum(np.power(letterseq,2))/len(letterseq) #incelenecek\n",
    "#entropi\n",
    "entropi = forEntropi.entropy(letterseq)\n",
    "#Spectrum\n",
    "dalgaBoyu = spectrum(letterseq)\n",
    "\n",
    "print(\"Standard Deviation = \" , stdeviation)\n",
    "print(\"Mean Value = \" , meanvalue)\n",
    "print(\"Entropi Value = \" , entropi)\n",
    "print(\"Basit kare integrali = \" , squarepower)\n",
    "print(\"Dalga boyu = \" , dalgaBoyu)\n",
    "\n",
    "\n",
    "\n",
    "data=pd.read_excel('BThTest.xlsx', index_col=0,dtype={'Name': str, 'Value': float})\n",
    "\n",
    "print(data)\n",
    "X=data.iloc[:, 0:6].values\n",
    "Y=data.iloc[:,:6].values\n",
    "\n",
    "\n",
    "\n",
    "le=LabelEncoder()\n",
    "X[:,1]=le.fit_transform(X[:,1])\n",
    "\n",
    "le2=LabelEncoder()\n",
    "X[:,2]=le.fit_transform(X[:,2])\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe=OneHotEncoder(categorical_features=[1])\n",
    "X=ohe.fit_transform(X).toarray()\n",
    "X=X[:,1:]\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, shuffle=True,\n",
    "                                                    test_size=0.33, random_state=50)\n",
    "\n",
    "#Ölçeklendirme\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X_train=sc.fit_transform(x_train)\n",
    "X_test=sc.fit_transform(x_test)\n",
    "\n",
    "#sınıflandırma yapılacak\n",
    "\n",
    "classifier=Sequential()\n",
    "classifier.add(Dense(3,init='uniform',activation='relu',input_dim=5))\n",
    "classifier.add(Dense(3,init='uniform',activation='relu'))\n",
    "classifier.add(Dense(1,init='uniform',activation='sigmoid'))\n",
    "\n",
    "\n",
    "classifier.compile(optimizer='adam',loss='binary_crossentropy', metrics=['accuracy'] )\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "classifier.fit(X_train,y_train,epochs=50)\n",
    "\n",
    "y_pred=classifier.predict(X_test)\n",
    "y_pred=(y_pred > 0.5)\n",
    "from sklearn.metrices import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_pred)\n",
    "\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
